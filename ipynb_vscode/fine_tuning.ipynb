{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "\n",
    "my_api_key = 'my_api_key'\n",
    "\n",
    "openai.api_key = my_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded with ID: file-J9p8IAivKnMMfVu0ksN0UilB\n"
     ]
    }
   ],
   "source": [
    "# 1. Upload a dataset\n",
    "response = openai.files.create(\n",
    "    file=open(\"dataset.jsonl\", \"rb\"),\n",
    "    purpose='fine-tune'\n",
    ")\n",
    "\n",
    "file_id = response.id\n",
    "print(f\"Uploaded with ID: {file_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune job ID: ftjob-FkoMxTY0LA8ogvbSM3WVtNbP\n"
     ]
    }
   ],
   "source": [
    "# 2. Create a fine-tuning job\n",
    "response = openai.fine_tuning.jobs.create(\n",
    "    training_file = file_id,\n",
    "    model = 'gpt-4o-mini-2024-07-18',\n",
    ")\n",
    "fine_tune_id = response.id\n",
    "print(f\"Fine-tune job ID: {fine_tune_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Monitor the fine-tuning job\n",
    "while True:\n",
    "    response = openai.fine_tuning.jobs.retrieve(fine_tune_id)\n",
    "    status = response.status\n",
    "    if status in [\"succeeded\", \"failed\"]:\n",
    "        break\n",
    "    print(f\"Fine-tune job status: {status}\")\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning failed.\n"
     ]
    }
   ],
   "source": [
    "if status == 'succeeded':\n",
    "    # 4. Use the fine-tuned model\n",
    "    response = openai.Completion.create(\n",
    "        model=response.fine_tuned_model,\n",
    "        prompt = \"Traslate the following sentence to Korean: 'Good morning!'\\n\\n###\\n\\n\",\n",
    "        max_tokens=50\n",
    "    )\n",
    "    print(f\"Fine-tuned model output: {response.choices[0].text.script()}\")\n",
    "else:\n",
    "    print(\"Fine-tuning failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-J4prRrIT8YHh6qwFEOG2BRSp/user-pvKLZYvlF3o3mYR4mfwywayH/img-tyzm519cLCAMQm8JWGAk3LH4.png?st=2024-11-18T11%3A31%3A12Z&se=2024-11-18T13%3A31%3A12Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-11-18T00%3A43%3A47Z&ske=2024-11-19T00%3A43%3A47Z&sks=b&skv=2024-08-04&sig=hJ6c4CxaKDgm9LNmO9IyVeCoQEZhnl24uj6LngeXmNk%3D\n",
      "Image saved as generated_image.png\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_api_key)\n",
    "\n",
    "# 이미지 생성 함수\n",
    "def generate_image(prompt):\n",
    "    response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=prompt,\n",
    "        size=\"1024x1024\",\n",
    "        quality=\"standard\",\n",
    "        n=1,\n",
    "    )\n",
    "    image_url = response.data[0].url  # 이미지 URL 가져오기\n",
    "    return image_url\n",
    "\n",
    "# 예시 prompt\n",
    "prompt = \"An orange cat sleeping next to a student during the lecture\"\n",
    "\n",
    "# 이미지 저장 함수\n",
    "def save_image(image_url, filename):\n",
    "    response = requests.get(image_url)  # 이미지 URL에서 이미지 가져오기\n",
    "    image = Image.open(BytesIO(response.content))  # 이미지를 BytesIO로 로드\n",
    "    image.save(filename)  # 로컬 파일로 저장\n",
    "\n",
    "# 이미지 생성\n",
    "image_url = generate_image(prompt)\n",
    "print(f\"Image URL: {image_url}\")\n",
    "\n",
    "# 이미지를 파일로 저장\n",
    "save_image(image_url, \"generated_image.png\")\n",
    "print(\"Image saved as generated_image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload response:  FileObject(id='file-MQcdnkKnOQ4cGptFLif2lmrZ', bytes=281, created_at=1731975390, filename='dataset.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "upload_response = client .files.create(\n",
    "    file = open(\"dataset.jsonl\", \"rb\"),\n",
    "    purpose = \"fine-tune\"\n",
    ")\n",
    "print('Upload response: ', upload_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Response:\n",
      "<bound method Files.list of <openai.resources.files.Files object at 0x119c28ce0>>\n",
      "Retrieve Response:\n",
      "FileObject(id='file-MQcdnkKnOQ4cGptFLif2lmrZ', bytes=281, created_at=1731975390, filename='dataset.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Delete Response:\n",
      "FileDeleted(id='file-MQcdnkKnOQ4cGptFLif2lmrZ', deleted=True, object='file')\n"
     ]
    }
   ],
   "source": [
    "# 모든 파일 나열\n",
    "list_response = client.files.list\n",
    "print(\"List Response:\")\n",
    "print(list_response)\n",
    "\n",
    "# 특정 파일 검색\n",
    "file_id = 'file-MQcdnkKnOQ4cGptFLif2lmrZ'  # 업로드된 파일 ID를 사용\n",
    "retrieve_response = client.files.retrieve(file_id=file_id)\n",
    "print(\"Retrieve Response:\")\n",
    "print(retrieve_response)\n",
    "\n",
    "# 파일 삭제\n",
    "delete_response = client.files.delete(file_id)\n",
    "print(\"Delete Response:\")\n",
    "print(delete_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription Resopnse: Transcription(text='Your hands lie open in the long, fresh grass. The finger points look through like rosy blooms. Your eyes smile peace. The pasture gleams and glooms neath billowing skies that scatter and amass. All round our nest, far as the eye can pass, our golden king cup feels with silver edge, where the cow partially skirts the hawthorn hedge, disvisible silence still is the hourglass. Your hands lie open in the long, fresh grass. The finger points look through like rosy blooms. Your eyes smile peace. The pasture gleams and glooms neath billowing skies that scatter and amass. All round our nest, far as the eye can pass, our golden king cup feels with silver edge, where the cow partially skirts the hawthorn hedge, disvisible silence still is the hourglass.')\n"
     ]
    }
   ],
   "source": [
    "def transcribe_audio(file_path, model=\"whisper-1\", response_format=\"json\", language=None, prompt = None):\n",
    "    with open(file_path, \"rb\") as audio_file:\n",
    "        reponse = client.audio.transcriptions.create(\n",
    "            file = audio_file,\n",
    "            model = model,\n",
    "            response_format = response_format,\n",
    "            language = language,\n",
    "            prompt = prompt\n",
    "        )\n",
    "    return reponse\n",
    "\n",
    "# Audio file path\n",
    "file_path = \"audio.mp3\"\n",
    "\n",
    "# Transcribe the audio file\n",
    "transcription = transcribe_audio(file_path)\n",
    "print(\"Transcription Resopnse:\", transcription)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
